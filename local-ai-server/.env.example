# OJT Master - Local AI Server 환경 설정
# 이 파일을 .env로 복사하여 사용하세요

# ============================================
# 모델 설정
# ============================================

# Qwen3 모델 선택 (VRAM 요구량)
# - Qwen/Qwen3-0.6B  : ~1GB  (저사양)
# - Qwen/Qwen3-1.7B  : ~2GB  (가벼움)
# - Qwen/Qwen3-4B    : ~4GB  (권장)
# - Qwen/Qwen3-8B    : ~8GB  (고성능)
# - Qwen/Qwen3-14B   : ~14GB (고성능, RTX 4090+)
# - Qwen/Qwen3-32B   : ~32GB (최고성능, A100+)
MODEL_NAME=Qwen/Qwen3-4B

# 최대 컨텍스트 길이 (토큰 수)
# 길수록 긴 문서 처리 가능, VRAM 더 필요
MAX_MODEL_LEN=8192

# GPU 메모리 사용률 (0.0 ~ 1.0)
# 다른 작업도 해야 하면 낮춤 (예: 0.7)
GPU_MEMORY_UTIL=0.9

# ============================================
# 서버 설정
# ============================================

# API 서버 포트
PORT=8000

# Ollama 포트 (옵션 2 사용 시)
OLLAMA_PORT=11434

# ============================================
# 인증 (선택)
# ============================================

# HuggingFace 토큰 (Gated 모델 사용 시 필요)
# https://huggingface.co/settings/tokens
HF_TOKEN=

# ============================================
# OJT Master 연동
# ============================================
# OJT Master의 .env 파일에 아래 추가:
# VITE_LOCAL_AI_URL=http://<이 서버 IP>:8000
